{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Guitar Melody Transcription Project\n",
    "This notebook contains the code for a Machine Learning project with the goal of transcribing guitar melodies from a recording. The process involves generating audio from MIDIs in various soundfonts, slicing the spectrogram, and feeding these slices into a model to recreate the MIDI notes as one-hot encoded arrays."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1: MIDI Generation"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import random\n",
    "from music21 import stream, note, clef, midi, instrument\n",
    "\n",
    "# Constants\n",
    "LOWEST_NOTE = 40  # MIDI number for E2\n",
    "HIGHEST_NOTE = 88  # MIDI number for E6\n",
    "NOTE_PROBABILITY = 0.7  # Probability of a note being played instead of a rest\n",
    "NUM_MEASURES = 4\n",
    "NOTES_PER_MEASURE = 16  # 16 sixteenth-notes per measure\n",
    "DURATIONS = [0.25, 0.5, 1.0, 2.0, 4.0]  # 16th, 8th, quarter, half, whole\n",
    "MAX_ACTIVE_NOTES = 5\n",
    "\n",
    "def biased_note_choice():\n",
    "    \"\"\"Randomly select note, but certain note ranges are more favored.\"\"\"\n",
    "    ranges = {'low': (40, 60), 'middle': (61, 73), 'high': (74, 88)}\n",
    "    probabilities = {'low': 0.5, 'middle': 0.35, 'high': 0.15}\n",
    "    selected_range = random.choices(list(ranges.keys()), weights=list(probabilities.values()), k=1)[0]\n",
    "    return random.randint(*ranges[selected_range])\n",
    "\n",
    "def generate_melody():\n",
    "    \"\"\"Generate a random melody with constraints for note range and duration.\"\"\"\n",
    "    melody = stream.Part()\n",
    "    melody.append(clef.TrebleClef())\n",
    "    \n",
    "    # Guitar instrument lines up with Bank 0 preset 24\n",
    "    gen_inst = instrument.Guitar()\n",
    "    melody.insert(0, gen_inst)\n",
    "\n",
    "    current_time = 0.0\n",
    "    max_time = NUM_MEASURES * 4.0  # time is measured in quarter note proportions\n",
    "    \n",
    "    active_notes = []  # lets us keep track of num notes active\n",
    "\n",
    "    while current_time < max_time:\n",
    "        if random.random() < NOTE_PROBABILITY:  # If note (else rest)\n",
    "            note_duration = random.choice(DURATIONS)\n",
    "            if current_time + note_duration > max_time:\n",
    "                note_duration = max_time - current_time\n",
    "\n",
    "            midi_note = biased_note_choice()  # returns int note id\n",
    "            new_note = note.Note(midi=midi_note, quarterLength=note_duration)\n",
    "            active_notes = [(start, end, n) for start, end, n in active_notes if end > current_time]\n",
    "            \n",
    "            if len(active_notes) < MAX_ACTIVE_NOTES:  # If we can insert note (else rest)\n",
    "                melody.insert(current_time, new_note)\n",
    "                active_notes.append((current_time, current_time + note_duration, new_note))\n",
    "            else:\n",
    "                melody.insert(current_time, note.Rest(quarterLength=0.25))\n",
    "        else:\n",
    "            melody.insert(current_time, note.Rest(quarterLength=0.25))\n",
    "        current_time += 0.25  # increment one 16th\n",
    "\n",
    "    return melody\n",
    "\n",
    "def generate_random_basic(filename):\n",
    "    \"\"\"Generate a random MIDI file and save it to disk.\"\"\"\n",
    "    melody = generate_melody()\n",
    "\n",
    "    # Save to file\n",
    "    midi_filename = 'MIDIs/' + filename + '.mid'\n",
    "    mf = midi.translate.music21ObjectToMidiFile(melody)\n",
    "    mf.open(midi_filename, 'wb')\n",
    "    mf.write()\n",
    "    mf.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2: MIDI to WAV Conversion"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import subprocess\n",
    "\n",
    "def convert(filename, soundfont_path):\n",
    "    \"\"\"Convert a MIDI file to WAV using FluidSynth.\"\"\"\n",
    "    # Paths\n",
    "    midi_file_path = 'MIDIs/'+filename+'.mid'\n",
    "    output_wav_path = 'WAVs/'+filename+'.wav'\n",
    "\n",
    "    # FluidSynth command\n",
    "    command = [\n",
    "        'fluidsynth',\n",
    "        '-ni',\n",
    "        soundfont_path,\n",
    "        midi_file_path,\n",
    "        '-F', output_wav_path,\n",
    "        '-r', '44100'\n",
    "    ]\n",
    "\n",
    "    # Run the FluidSynth command\n",
    "    result = subprocess.run(command, capture_output=True, text=True)\n",
    "\n",
    "    # Check result\n",
    "    if result.returncode == 0:\n",
    "        print('MIDI has been successfully converted to WAV.')\n",
    "    else:\n",
    "        print('Error converting MIDI to WAV:')\n",
    "        print(result.stderr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3: Tensor Generation"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from scipy.io import wavfile\n",
    "from scipy.signal import spectrogram, butter, filtfilt\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import mido\n",
    "\n",
    "# ---WAV PROCESSING---\n",
    "\n",
    "def normalize_array(array):\n",
    "    if np.ptp(array) == 0:  # Check if the array has zero range\n",
    "        return np.zeros(array.shape, dtype=np.uint8)\n",
    "    normalized_array = 255 * (array - np.min(array)) / np.ptp(array)\n",
    "    return normalized_array.astype(np.uint8)\n",
    "\n",
    "def bandpass_filter(data, lowcut, highcut, sample_rate, order=5):\n",
    "    nyquist = 0.5 * sample_rate\n",
    "    low = lowcut / nyquist\n",
    "    high = highcut / nyquist\n",
    "    b, a = butter(order, [low, high], btype='band')\n",
    "    y = filtfilt(b, a, data)\n",
    "    return y\n",
    "\n",
    "def create_amplitude_tensors(filename, bpm):\n",
    "    wav_file = 'WAVs/' + filename + '.wav'\n",
    "    output_file = 'Spectrograms/' + filename + '.png'\n",
    "\n",
    "    # Load the WAV file\n",
    "    sample_rate, data = wavfile.read(wav_file)\n",
    "\n",
    "    # If stereo, convert to mono by averaging the channels\n",
    "    if len(data.shape) == 2:\n",
    "        data = data.mean(axis=1)\n",
    "\n",
    "    # Apply the band-pass filter\n",
    "    lowcut = 70  # E2 frequency in Hz\n",
    "    highcut = 1700  # E6 frequency in Hz\n",
    "    data = bandpass_filter(data, lowcut, highcut, sample_rate)\n",
    "\n",
    "    # Calculate the spectrogram with a larger FFT window size\n",
    "    nperseg = 4094  # Larger window size for better frequency resolution\n",
    "    noverlap = nperseg // 1.5  # Strange grey bars appear for values greater than 1.5\n",
    "\n",
    "    frequencies, times, Sxx = spectrogram(data, fs=sample_rate, window='hann', nperseg=nperseg, noverlap=noverlap)\n",
    "\n",
    "    # Convert the spectrogram (power spectral density) to decibels\n",
    "    Sxx_dB = 10 * np.log10(Sxx + 1e-10)  # Adding a small number to avoid log(0)\n",
    "\n",
    "    Sxx_dB = Sxx_dB[:][:512]\n",
    "\n",
    "    # Normalize the values between 0 and 255\n",
    "    img_array = np.uint8(255 * (Sxx_dB - np.min(Sxx_dB)) / np.ptp(Sxx_dB))\n",
    "    \n",
    "    # Convert to Image and save as PNG\n",
    "    image = Image.fromarray(img_array)\n",
    "    image.save(output_file)\n",
    "\n",
    "    # Calculate the duration of a 32nd note in seconds\n",
    "    beats_per_second = bpm / 60\n",
    "    seconds_per_beat = 1 / beats_per_second\n",
    "    seconds_per_32nd_note = seconds_per_beat / 8  # 32nd note duration\n",
    "\n",
    "    # Determine the number of time slices for each 32nd note duration\n",
    "    num_slices = int(np.ceil(times[-1] / seconds_per_32nd_note))\n",
    "\n",
    "    # List to store the average values of each vertical slice\n",
    "    avg_slices = []\n",
    "\n",
    "    # Iterate over each 32nd note slice\n",
    "    for i in range(num_slices):\n",
    "        # Determine the start and end time for this slice\n",
    "        start_time = i * seconds_per_32nd_note\n",
    "        end_time = (i + 1) * seconds_per_32nd_note\n",
    "\n",
    "        # Find the indices in the time array that correspond to this slice\n",
    "        start_idx = np.searchsorted(times, start_time)\n",
    "        end_idx = np.searchsorted(times, end_time)\n",
    "\n",
    "        # Get the slice of the spectrogram for this time period\n",
    "        slice_Sxx_dB = Sxx_dB[:, start_idx:end_idx]\n",
    "\n",
    "        # Calculate the average value of each vertical pixel in this slice\n",
    "        avg_values = np.mean(slice_Sxx_dB, axis=1)\n",
    "        avg_slices.append(avg_values)\n",
    "\n",
    "    # Convert the list of average slices to a numpy array for further processing\n",
    "    avg_slices_array = np.array(avg_slices)\n",
    "    \n",
    "    return avg_slices_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MIDI Processing Functions"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def load_midi(file_path):\n",
    "    \"\"\"Load the MIDI file and return the messages with their cumulative times.\"\"\"\n",
    "    midi_file = mido.MidiFile(file_path)\n",
    "    messages_with_time = []\n",
    "\n",
    "    # Initialize the current time\n",
    "    current_time = 0\n",
    "\n",
    "    for message in midi_file:\n",
    "        # Increment the current time by the time of the current message\n",
    "        current_time += message.time\n",
    "        # Append the message with the cumulative time to the list\n",
    "        messages_with_time.append((current_time, message))\n",
    "\n",
    "    return messages_with_time\n",
    "\n",
    "def get_note_periods(messages_with_time):\n",
    "    \"\"\"Get the time periods for each note.\"\"\"\n",
    "    note_periods = []\n",
    "    notes_on = {}\n",
    "\n",
    "    for time, message in messages_with_time:\n",
    "        if message.type == 'note_on' and message.velocity > 0:\n",
    "            if message.note not in notes_on:\n",
    "                notes_on[message.note] = []\n",
    "            notes_on[message.note].append(time)\n",
    "        elif message.type == 'note_off' or (message.type == 'note_on' and message.velocity == 0):\n",
    "            if message.note in notes_on and notes_on[message.note]:\n",
    "                start_time = notes_on[message.note].pop()\n",
    "                note_periods.append((message.note, start_time, time))\n",
    "\n",
    "    # If there are notes that were not turned off, handle them appropriately\n",
    "    for note, times in notes_on.items():\n",
    "        for start_time in times:\n",
    "            note_periods.append((note, start_time, messages_with_time[-1][0]))\n",
    "\n",
    "    return note_periods\n",
    "\n",
    "def create_note_dict(note_periods):\n",
    "    \"\"\"Create a dictionary of note periods.\"\"\"\n",
    "    note_dict = {}\n",
    "    note_id = 0\n",
    "\n",
    "    for note, start_time, end_time in note_periods:\n",
    "        note_dict[note_id] = [note, (start_time, end_time)]\n",
    "        note_id += 1\n",
    "\n",
    "    return note_dict\n",
    "\n",
    "def get_notes_in_32nd_period(note_dict, start_time, end_time):\n",
    "    \"\"\"Get one-hot encoded notes for a specific 32nd-note period.\"\"\"\n",
    "    notes_playing = set()\n",
    "    period_duration = end_time - start_time\n",
    "    threshold = period_duration / 2\n",
    "\n",
    "    for note_info in note_dict.values():\n",
    "        note, (note_start, note_end) = note_info\n",
    "        overlap_start = max(note_start, start_time)\n",
    "        overlap_end = min(note_end, end_time)\n",
    "        overlap_duration = overlap_end - overlap_start\n",
    "\n",
    "        if overlap_duration > threshold:\n",
    "            notes_playing.add(note)\n",
    "\n",
    "    # Create a one-hot encoded array for notes 40 to 88\n",
    "    one_hot_array = [0] * (88 - 40 + 1)\n",
    "    for note in notes_playing:\n",
    "        if 40 <= note <= 88:\n",
    "            one_hot_array[note - 40] = 1\n",
    "\n",
    "    return one_hot_array\n",
    "\n",
    "def get_all_32nd_note_periods(note_dict, start_time, end_time, period_duration):\n",
    "    \"\"\"Generate one-hot encoded arrays for all 32nd-note periods.\"\"\"\n",
    "    current_time = start_time\n",
    "    periods = []\n",
    "\n",
    "    while current_time < end_time:\n",
    "        next_time = current_time + period_duration\n",
    "        one_hot_array = get_notes_in_32nd_period(note_dict, current_time, next_time)\n",
    "        periods.append(one_hot_array)\n",
    "        current_time = next_time\n",
    "\n",
    "    return periods\n",
    "\n",
    "def create_midi_tensors(file_path):\n",
    "    \"\"\"Main function to load the MIDI file and get one-hot encoded note periods.\"\"\"\n",
    "    messages_with_time = load_midi(file_path)\n",
    "    note_periods = get_note_periods(messages_with_time)\n",
    "    note_dict = create_note_dict(note_periods)\n",
    "    \n",
    "    one_hot_encoded_periods = get_all_32nd_note_periods(note_dict, 0, 8, 0.0625)\n",
    "    return np.array(one_hot_encoded_periods)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main Function to Build Tensors"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def build_tensors(filename, bpm):\n",
    "    midi_list = create_midi_tensors('MIDIs/' + filename + '.mid')\n",
    "    amplitudes_list = create_amplitude_tensors(filename, bpm)\n",
    "    if len(midi_list) > len(amplitudes_list):\n",
    "        print(\"Error: amplitude list smaller than midi list for unknown reason, aborting...\")\n",
    "        return []\n",
    "    master_list = [[amplitudes_list[i], midi_list[i]] for i in range(len(midi_list))]\n",
    "    return master_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 4: Model Training and Prediction"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# Parsing function\n",
    "def _parse_function(proto):\n",
    "    keys_to_features = {\n",
    "        'spectrogram': tf.io.FixedLenFeature([512], tf.float32),\n",
    "        'notes': tf.io.FixedLenFeature([49], tf.int64)\n",
    "    }\n",
    "    parsed_features = tf.io.parse_single_example(proto, keys_to_features)\n",
    "    return parsed_features['spectrogram'], parsed_features['notes']\n",
    "\n",
    "# Augmentation functions\n",
    "def add_noise(spectrogram, noise_factor=0.005):\n",
    "    noise = np.random.randn(*spectrogram.shape) * noise_factor\n",
    "    return spectrogram + noise\n",
    "\n",
    "def amplitude_scaling(spectrogram, scale_range=(0.9, 1.1)):\n",
    "    scale = np.random.uniform(scale_range[0], scale_range[1])\n",
    "    return spectrogram * scale\n",
    "\n",
    "def augment_data(spectrogram, notes):\n",
    "    spectrogram = add_noise(spectrogram).astype(np.float32)\n",
    "    spectrogram = amplitude_scaling(spectrogram).astype(np.float32)\n",
    "    return spectrogram, notes\n",
    "\n",
    "def tf_augment_data(spectrogram, notes):\n",
    "    spectrogram, notes = tf.numpy_function(augment_data, [spectrogram, notes], [tf.float32, tf.int64])\n",
    "    spectrogram.set_shape([512])  # Explicitly set the shape\n",
    "    notes.set_shape([49])          # Explicitly set the shape\n",
    "    return spectrogram, notes\n",
    "\n",
    "# Directory containing TFRecord files\n",
    "tfrecord_dir = 'GeneratedData'\n",
    "\n",
    "# Get list of all TFRecord files\n",
    "tfrecord_files = [os.path.join(tfrecord_dir, f) for f in os.listdir(tfrecord_dir) if f.endswith('.tfrecord')]\n",
    "\n",
    "# Create a dataset from the TFRecord files\n",
    "raw_dataset = tf.data.TFRecordDataset(tfrecord_files)\n",
    "\n",
    "# Parse the dataset\n",
    "parsed_dataset = raw_dataset.map(_parse_function)\n",
    "\n",
    "# Augment the dataset\n",
    "augmented_dataset = parsed_dataset.map(tf_augment_data)\n",
    "\n",
    "# Shuffle, batch, and prefetch the dataset\n",
    "batch_size = 32\n",
    "dataset = augmented_dataset.shuffle(buffer_size=10000).batch(batch_size).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "\n",
    "# Define the model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(512, 1)),\n",
    "\n",
    "    tf.keras.layers.Conv1D(filters=32, kernel_size=3, activation='relu', padding='same'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.MaxPooling1D(pool_size=2),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "\n",
    "    tf.keras.layers.Conv1D(filters=64, kernel_size=3, activation='relu', padding='same'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.MaxPooling1D(pool_size=2),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "\n",
    "    tf.keras.layers.Conv1D(filters=128, kernel_size=3, activation='relu', padding='same'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.MaxPooling1D(pool_size=2),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    tf.keras.layers.Dense(256, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    tf.keras.layers.Dense(49, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(dataset, epochs=80, validation_data=dataset, validation_steps=80, callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)])\n",
    "\n",
    "model_save_path = '*saved_tf_models/BasicConvGuitarNotePredictor(512_input).keras'\n",
    "\n",
    "# Save the model\n",
    "model.save(model_save_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
